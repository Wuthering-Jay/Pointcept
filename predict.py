"""
Predict script for LAS point cloud segmentation (Fully Isolated Pipeline Version).

Fixes:
1. Memory Leak: Replaces ProcessPoolExecutor with mp.Process for CPU tasks to ensure 100% memory reclamation.
2. Temp Files: Moves cleanup logic to `finally` blocks to guarantee execution.
3. Performance: Maintains Pipeline Parallelism.

Author: Generated by GitHub Copilot & Optimized for Stability
"""
import utils.numpy_compat_1to2
import os
import sys
import shutil
import tempfile
import time
import logging
import gc
import traceback
from datetime import datetime, timedelta
from typing import Optional, Tuple, List, Dict, Any
from pathlib import Path
import queue

import numpy as np
import laspy
import torch
import torch.multiprocessing as mp

# Fix OpenMP conflicts
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
os.environ['OMP_NUM_THREADS'] = '4'

# Ensure project root is in path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from pointcept.engines.defaults import default_config_parser, default_setup
from pointcept.engines.test import TESTERS
from pointcept.models import build_model
from pointcept.utils import comm

def setup_logger(log_dir: str, name: str = "predict") -> logging.Logger:
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(log_dir, f"{name}_{timestamp}.log")
    
    fh = logging.FileHandler(log_file, encoding='utf-8')
    fh.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
    logger.addHandler(fh)
    
    ch = logging.StreamHandler(sys.stdout)
    ch.setFormatter(logging.Formatter('%(message)s'))
    logger.addHandler(ch)
    return logger

def cleanup_cache():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

# =========================================================================
#  Stage 1: Pre-processing (CPU - Isolated)
# =========================================================================

def stage1_worker_func(
    result_queue: mp.Queue, 
    las_file_path: str,
    temp_root_dir: str,
    require_labels: Optional[List[int]],
    ignore_labels: Optional[List[int]],
    window_size: Tuple[float, float],
    min_points: Optional[int],
    max_points: Optional[int]
):
    las_file = Path(las_file_path)
    temp_base_dir = None
    try:
        temp_base_dir = tempfile.mkdtemp(prefix=f"proc_{las_file.stem}_", dir=temp_root_dir)
        
        dirs = {
            "base": temp_base_dir,
            "extract_predict": os.path.join(temp_base_dir, "1_extract"),
            "extract_excluded": os.path.join(temp_base_dir, "1_excluded"),
            "tile": os.path.join(temp_base_dir, "2_tile"),
            "pred": os.path.join(temp_base_dir, "3_pred"),
            "merge": os.path.join(temp_base_dir, "4_merge"),
            "final": os.path.join(temp_base_dir, "5_final"),
        }
        for d in dirs.values():
            os.makedirs(d, exist_ok=True)

        print(f"[Pre-proc] Start: {las_file.name}")
        
        from utils.las_tile import process_las_tiles
        
        file_info = {}
        tile_input_dir = dirs["extract_predict"]
        las_data = laspy.read(las_file)
        
        # Fix: Upgrade LAS version to 1.2 if it's 1.0 or 1.1 to avoid compatibility issues
        if las_data.header.version.major == 1 and las_data.header.version.minor < 2:
            from laspy.header import Version
            las_data.header.version = Version(1, 2)
        
        if not hasattr(las_data, 'classification') or (require_labels is None and ignore_labels is None):
            las_data.write(Path(tile_input_dir) / las_file.name)
            file_info[las_file.stem] = {"has_excluded": False}
        else:
            labels = np.array(las_data.classification)
            if require_labels is not None:
                predict_mask = np.isin(labels, require_labels)
            else:
                predict_mask = ~np.isin(labels, ignore_labels)
            
            excluded_mask = ~predict_mask
            
            if not np.any(predict_mask):
                excluded_file = Path(dirs["extract_excluded"]) / las_file.name
                las_data.write(excluded_file)
                file_info[las_file.stem] = {"has_excluded": True, "excluded_file": str(excluded_file), "all_excluded": True}
            elif not np.any(excluded_mask):
                las_data.write(Path(tile_input_dir) / las_file.name)
                file_info[las_file.stem] = {"has_excluded": False}
            else:
                predict_las = laspy.LasData(las_data.header)
                predict_las.points = las_data.points[predict_mask]
                predict_las.update_header()
                predict_las.write(Path(tile_input_dir) / las_file.name)
                
                excluded_las = laspy.LasData(las_data.header)
                excluded_las.points = las_data.points[excluded_mask]
                excluded_las.update_header()
                excluded_file = Path(dirs["extract_excluded"]) / f"{las_file.stem}_excluded.las"
                excluded_las.write(excluded_file)
                
                file_info[las_file.stem] = {
                    "has_excluded": True, 
                    "excluded_file": str(excluded_file),
                    "all_excluded": False
                }
        
        del las_data
        gc.collect()

        if not file_info.get(las_file.stem, {}).get("all_excluded", False):
            process_las_tiles(
                input_path=tile_input_dir,
                output_dir=dirs["tile"],
                window_size=window_size,
                min_points=min_points,
                max_points=max_points,
                label_remap=False,
                label_count=False,
                save_sample_weight=False
            )
        
        result_queue.put({
            "status": "success",
            "las_file_stem": las_file.stem,
            "las_file_path": str(las_file_path),
            "dirs": dirs,
            "file_info": file_info
        })

    except Exception as e:
        print(f"[Pre-proc] Error: {e}")
        traceback.print_exc()
        if temp_base_dir and os.path.exists(temp_base_dir):
            try: shutil.rmtree(temp_base_dir)
            except: pass
        result_queue.put({
            "status": "error", 
            "error": str(e), 
            "las_file_stem": las_file.stem,
            "las_file_path": str(las_file_path)
        })

# =========================================================================
#  Stage 2: Persistent Inference Worker (GPU)
# =========================================================================

def inference_worker_loop(
    input_queue: mp.Queue, 
    result_queue: mp.Queue, 
    config_file: str, 
    weight_file: str, 
    num_gpus: int, 
    enable_amp: bool,
    restart_limit: int
):
    try:
        comm.synchronize()
        project_root = os.path.dirname(os.path.abspath(__file__))
        if not os.path.isabs(config_file):
            config_file_abs = os.path.join(project_root, config_file)
        else:
            config_file_abs = config_file

        with open(config_file_abs, 'r', encoding='utf-8') as f:
            cfg_str = f.read()
            
        base_ref_short = "../_base_/default_runtime.py"
        correct_base_path = os.path.join(project_root, "configs", "_base_", "default_runtime.py").replace(os.sep, "/")
        if base_ref_short in cfg_str and not os.path.exists(os.path.join(os.path.dirname(config_file_abs), base_ref_short)):
            cfg_str = cfg_str.replace(f"'{base_ref_short}'", f"'{correct_base_path}'")
            cfg_str = cfg_str.replace(f'"{base_ref_short}"', f'"{correct_base_path}"')

        temp_cfg_path = os.path.join(tempfile.gettempdir(), f"pointcept_cfg_{os.getpid()}.py")
        with open(temp_cfg_path, 'w', encoding='utf-8') as f:
            f.write(cfg_str)

        options = {
            "weight": weight_file,
            "enable_amp": enable_amp,
            "data.test.split": "",
            "batch_size_test": 1,
            "num_worker": 2,
        }
        cfg = default_config_parser(temp_cfg_path, options)
        cfg = default_setup(cfg)
        
        print(f"[Inference-Worker-{os.getpid()}] Loading Model...")
        model = build_model(cfg.model).cuda()
        checkpoint = torch.load(cfg.weight, map_location="cuda", weights_only=False)
        model.load_state_dict(checkpoint["state_dict"], strict=False)
        model.eval()
        print(f"[Inference-Worker-{os.getpid()}] Model Loaded.")

        processed_count = 0
        
        while True:
            task = input_queue.get()
            if task is None: break
                
            dirs = task["dirs"]
            las_stem = task["las_file_stem"]
            las_file_path = task.get("las_file_path")
            
            try:
                tile_dir = dirs["tile"]
                pred_dir = dirs["pred"]
                tiles = [f for f in os.listdir(tile_dir) if f.endswith('.las')]
                
                if tiles:
                    for f in tiles:
                        shutil.copy2(os.path.join(tile_dir, f), os.path.join(pred_dir, f))
                    
                    cfg.data_root = pred_dir
                    cfg.data.test.data_root = pred_dir
                    
                    tester = TESTERS.build(dict(type=cfg.test.type, cfg=cfg, model=model))
                    tester.test()
                    del tester
                
                result_queue.put({"status": "success", "las_file_stem": las_stem, "las_file_path": las_file_path})
                
            except Exception as e:
                traceback.print_exc()
                result_queue.put({"status": "error", "error": str(e), "las_file_stem": las_stem, "las_file_path": las_file_path})
            
            processed_count += 1
            cleanup_cache()
            
            if restart_limit > 0 and processed_count >= restart_limit:
                print(f"[Inference-Worker-{os.getpid()}] Restart limit reached. Recycling.")
                result_queue.put("RESTART_NEEDED")
                break
                
    except Exception as e:
        print(f"[Inference-Worker-Init] Critical Error: {e}")
        traceback.print_exc()
        result_queue.put("CRITICAL_ERROR")
    finally:
        if 'temp_cfg_path' in locals() and os.path.exists(temp_cfg_path):
            try: os.remove(temp_cfg_path)
            except: pass

# =========================================================================
#  Stage 3: Post-processing (CPU - Isolated)
# =========================================================================

def stage3_worker_func(
    result_queue: mp.Queue,
    dirs: Dict[str, str],
    output_file_path: str,
    file_info: dict,
    label_remap_file: Optional[str],
    use_lac: bool,
    lac_dll_path: str,
    las_file_stem: str,
    las_file_path: str = None
):
    try:
        print(f"[Post-proc] Processing: {las_file_stem}")
        from utils.las_merge import merge_las_segments
        
        if file_info.get(las_file_stem, {}).get("all_excluded", False):
            excluded = file_info[las_file_stem]["excluded_file"]
            shutil.copy2(excluded, output_file_path)
            result_queue.put({"status": "success", "las_file_stem": las_file_stem, "las_file_path": las_file_path})
            return

        merge_las_segments(input_path=dirs["pred"], output_dir=dirs["merge"], label_remap_file=label_remap_file)
        
        final_dir = dirs["final"]
        merged_las_path = os.path.join(dirs["merge"], f"{las_file_stem}.las")
        if not os.path.exists(merged_las_path):
            candidates = [f for f in os.listdir(dirs["merge"]) if f.endswith('.las')]
            if candidates: merged_las_path = os.path.join(dirs["merge"], candidates[0])
        
        if os.path.exists(merged_las_path):
            if file_info[las_file_stem]["has_excluded"]:
                excluded_path = file_info[las_file_stem]["excluded_file"]
                pred_las = laspy.read(merged_las_path)
                excl_las = laspy.read(excluded_path)
                
                version = pred_las.header.version
                if version.major == 1 and version.minor < 2:
                    from laspy.header import Version
                    version = Version(1, 2)
                new_header = laspy.LasHeader(point_format=pred_las.header.point_format, version=version)
                new_header.offsets = pred_las.header.offsets
                new_header.scales = pred_las.header.scales
                
                # Copy extra dimensions to preserve all attributes (e.g., GPS Time, custom fields)
                for extra_dim in pred_las.point_format.extra_dimensions:
                    new_header.add_extra_dim(laspy.ExtraBytesParams(
                        name=extra_dim.name,
                        type=extra_dim.dtype,
                        description=extra_dim.description if hasattr(extra_dim, 'description') else ""
                    ))
                
                # Copy VLRs and CRS
                if hasattr(pred_las.header, 'vlrs'):
                    for vlr in pred_las.header.vlrs:
                        new_header.vlrs.append(vlr)
                
                total = len(pred_las.points) + len(excl_las.points)
                final_las = laspy.LasData(new_header)
                final_las.points = laspy.ScaleAwarePointRecord.zeros(total, header=new_header)
                
                split = len(pred_las.points)
                # Copy all standard dimensions
                for dim in pred_las.point_format.dimension_names:
                    getattr(final_las, dim)[:split] = getattr(pred_las, dim)
                for dim in excl_las.point_format.dimension_names:
                    if dim in pred_las.point_format.dimension_names:
                        getattr(final_las, dim)[split:] = getattr(excl_las, dim)
                
                # Copy extra dimensions (e.g., GPS Time, custom fields)
                for extra_dim in pred_las.point_format.extra_dimensions:
                    dim_name = extra_dim.name
                    if hasattr(pred_las, dim_name) and hasattr(final_las, dim_name):
                        getattr(final_las, dim_name)[:split] = getattr(pred_las, dim_name)
                for extra_dim in excl_las.point_format.extra_dimensions:
                    dim_name = extra_dim.name
                    if hasattr(excl_las, dim_name) and hasattr(final_las, dim_name):
                        getattr(final_las, dim_name)[split:] = getattr(excl_las, dim_name)
                
                final_las.update_header()
                final_las.write(os.path.join(final_dir, f"{las_file_stem}.las"))
                
                del pred_las, excl_las, final_las
            else:
                shutil.copy2(merged_las_path, final_dir)
        
        final_candidate = None
        for f in os.listdir(final_dir):
            if f.endswith('.las'): 
                final_candidate = os.path.join(final_dir, f)
                break
        
        if final_candidate:
            if use_lac:
                from utils.tin import batch_lac_process
                temp_lac = os.path.join(dirs["base"], "6_lac")
                os.makedirs(temp_lac, exist_ok=True)
                batch_lac_process(
                    input_dir=final_dir, output_dir=temp_lac,
                    use_tile=True, window_size=(500.0, 500.0), min_points=10000, dll_path=lac_dll_path
                )
                res = [f for f in os.listdir(temp_lac) if f.endswith('.las')]
                if res: shutil.copy2(os.path.join(temp_lac, res[0]), output_file_path)
            else:
                shutil.copy2(final_candidate, output_file_path)
        
        result_queue.put({"status": "success", "las_file_stem": las_file_stem, "las_file_path": las_file_path})
            
    except Exception as e:
        print(f"[Post-proc] Error: {e}")
        traceback.print_exc()
        result_queue.put({"status": "error", "error": str(e), "las_file_stem": las_file_stem, "las_file_path": las_file_path})
    finally:
        # FORCE CLEANUP
        try:
            if dirs and "base" in dirs and os.path.exists(dirs["base"]):
                shutil.rmtree(dirs["base"])
        except Exception as e:
            print(f"Error cleaning up temp dir: {e}")

# =========================================================================
#  Main Pipeline Controller
# =========================================================================

def predict_las(
    input_dir: str, output_dir: str, config_file: str, weight_file: str,
    require_labels: Optional[List[int]] = None, ignore_labels: Optional[List[int]] = None,
    window_size: Tuple[float, float] = (200.0, 200.0), min_points: Optional[int] = 5000,
    max_points: Optional[int] = None, label_remap_file: Optional[str] = None,
    use_lac: bool = False, lac_dll_path: str = r"libs\Release\LiDAROprationDLLEx.dll",
    num_gpus: int = 1, recursive: bool = False, enable_amp: bool = False,
    cache_cleanup_interval: Optional[int] = None,
    worker_restart_interval: int = 10,
):
    if require_labels is not None and ignore_labels is not None:
        raise ValueError("Cannot set both require_labels and ignore_labels")
    
    try: mp.set_start_method('spawn', force=True)
    except RuntimeError: pass

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    logger = setup_logger(os.path.dirname(weight_file))
    logger.info("=== Starting Persistent Pipeline Prediction (Fully Isolated CPU) ===")
    
    input_path = Path(input_dir)
    if input_path.is_file():
        las_files = [input_path]
    elif recursive:
        las_files = sorted(list(input_path.rglob("*.las")) + list(input_path.rglob("*.laz")))
    else:
        las_files = sorted(list(input_path.glob("*.las")) + list(input_path.glob("*.laz")))
    logger.info(f"Found {len(las_files)} files.")
    
    stage1_queue = mp.Queue()
    stage3_queue = mp.Queue() # New queue for Stage 3 tracking
    gpu_input_queue = mp.Queue()
    gpu_result_queue = mp.Queue()
    
    inference_process = mp.Process(
        target=inference_worker_loop,
        args=(gpu_input_queue, gpu_result_queue, config_file, weight_file, num_gpus, enable_amp, worker_restart_interval)
    )
    inference_process.start()
    
    pending_files = []
    for f in las_files:
        if input_path.is_file(): rel = f.name
        else:
            try: rel = f.relative_to(input_path)
            except: rel = f.name
        out = output_path / rel
        out.parent.mkdir(parents=True, exist_ok=True)
        pending_files.append((str(f), str(out)))
    
    total = len(pending_files)
    dispatched_to_preproc = 0
    completed_final = 0
    
    active_stage1_procs = []
    active_stage3_procs = []
    MAX_STAGE1_WORKERS = 2
    MAX_STAGE3_WORKERS = 2
    
    gpu_in_flight_map = {} 
    
    start_time = time.time()
    
    while completed_final < total:
        active_stage1_procs = [p for p in active_stage1_procs if p.is_alive()]
        active_stage3_procs = [p for p in active_stage3_procs if p.is_alive()]
        
        # 1. Dispatch Pre-proc
        while dispatched_to_preproc < total and \
              len(active_stage1_procs) < MAX_STAGE1_WORKERS and \
              len(gpu_in_flight_map) < 3:
            
            f_in, f_out = pending_files[dispatched_to_preproc]
            logger.info(f"[{dispatched_to_preproc+1}/{total}] Submitting Pre-proc: {Path(f_in).name}")
            
            p = mp.Process(
                target=stage1_worker_func,
                args=(stage1_queue, f_in, str(output_path), require_labels, ignore_labels, window_size, min_points, max_points)
            )
            p.start()
            active_stage1_procs.append(p)
            dispatched_to_preproc += 1
            
        # 2. Check Stage 1
        while not stage1_queue.empty():
            res = stage1_queue.get()
            stem = res["las_file_stem"]
            f_path = res.get("las_file_path")
            
            if res["status"] == "success":
                has_pred = not res["file_info"][stem].get("all_excluded", False)
                if has_pred:
                    gpu_in_flight_map[f_path] = res
                    gpu_input_queue.put(res)
                    logger.info(f"Sent to GPU Queue: {stem}")
                else:
                    curr_out = None
                    for p_in, p_out in pending_files:
                        if p_in == f_path:
                            curr_out = p_out
                            break
                    if curr_out:
                        p = mp.Process(
                            target=stage3_worker_func,
                            args=(stage3_queue, res["dirs"], curr_out, res["file_info"], label_remap_file, use_lac, lac_dll_path, stem, f_path)
                        )
                        p.start()
                        active_stage3_procs.append(p)
                    else:
                        completed_final += 1
            else:
                logger.error(f"Pre-proc failed for {stem}: {res.get('error')}")
                completed_final += 1
        
        # 3. Check GPU
        while not gpu_result_queue.empty():
            msg = gpu_result_queue.get()
            if msg == "RESTART_NEEDED":
                logger.info("Worker recycling...")
                inference_process.join()
                inference_process = mp.Process(
                    target=inference_worker_loop,
                    args=(gpu_input_queue, gpu_result_queue, config_file, weight_file, num_gpus, enable_amp, worker_restart_interval)
                )
                inference_process.start()
                continue
            if msg == "CRITICAL_ERROR":
                logger.error("GPU Worker Crashed.")
                for p in active_stage1_procs + active_stage3_procs: p.terminate()
                sys.exit(1)
            
            stem = msg.get("las_file_stem")
            f_path = msg.get("las_file_path")
            
            if msg["status"] == "success":
                logger.info(f"GPU Finished: {stem}")
                if f_path in gpu_in_flight_map:
                    res = gpu_in_flight_map.pop(f_path)
                    curr_out = None
                    for p_in, p_out in pending_files:
                        if p_in == f_path:
                            curr_out = p_out
                            break
                    
                    if curr_out:
                        while len(active_stage3_procs) >= MAX_STAGE3_WORKERS:
                            time.sleep(0.1)
                            active_stage3_procs = [p for p in active_stage3_procs if p.is_alive()]
                        
                        p = mp.Process(
                            target=stage3_worker_func,
                            args=(stage3_queue, res["dirs"], curr_out, res["file_info"], label_remap_file, use_lac, lac_dll_path, stem, f_path)
                        )
                        p.start()
                        active_stage3_procs.append(p)
                    else:
                        completed_final += 1
            else:
                logger.error(f"GPU Inference Failed for {stem}: {msg.get('error')}")
                if f_path in gpu_in_flight_map: 
                    try: shutil.rmtree(gpu_in_flight_map[f_path]["dirs"]["base"])
                    except: pass
                    del gpu_in_flight_map[f_path]
                completed_final += 1
        
        # 4. Check Stage 3
        while not stage3_queue.empty():
            res = stage3_queue.get()
            stem = res["las_file_stem"]
            if res["status"] == "success":
                logger.info(f"Completed: {stem}")
            else:
                logger.error(f"Post-proc failed for {stem}: {res.get('error')}")
            completed_final += 1
        
        time.sleep(0.05)

    gpu_input_queue.put(None)
    inference_process.join()
    
    total_time = time.time() - start_time
    logger.info(f"Pipeline Finished. Total Time: {str(timedelta(seconds=int(total_time)))}")

if __name__ == "__main__":
    # 示例用法
    INPUT_DIR = r"E:\data\铁二院\原始"
    OUTPUT_DIR = r"E:\data\铁二院\原始_预测结果"

    CONFIG_FILE = r"ckpt\other-1207\semseg-pt-v2m5-0-base.py"
    WEIGHT_FILE = r"ckpt\other-1207\model_best.pth"
    LABEL_REMAP_FILE = r"ckpt\other-1207\label_mapping.json"
    
    predict_las(
        input_dir=INPUT_DIR,
        output_dir=OUTPUT_DIR,
        config_file=CONFIG_FILE,
        weight_file=WEIGHT_FILE,
        require_labels=None,
        ignore_labels=[],
        window_size=(200.0, 200.0),
        min_points=5000,
        label_remap_file=LABEL_REMAP_FILE if LABEL_REMAP_FILE else None,
        use_lac=True,
        recursive=True,
        enable_amp=True,
        cache_cleanup_interval=25,
        worker_restart_interval=10
    )